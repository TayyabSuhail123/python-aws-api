# ğŸƒâ€â™‚ï¸ Minimal Agent-Runner â€“ Python API

Self-contained FastAPI service that launches **one agent at a time** and exposes
REST endpoints to start / monitor runs. Designed as a foundation for automating
insurance workflows yet small enough to grok in minutes.

---

## ğŸ¯ Why This Exists
- **Challenge goal:** Prove the ability to structure async Python, enforce a
  singleton task-runner, and reason about scalability, observability, and
  security.
- **Scope:** Focus on clean architecture & documentation; (Terraform,
  infra in another repo)

---

## ğŸ“ High-Level Architecture
```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  POST /agents/run   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Client     â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶  â”‚  FastAPI app â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚              â”‚
        â–²                         â”‚  asyncio.Lockâ”‚  (prevents concurrent runs)
        â”‚  GET /agents/status     â”‚              â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚  Agents      â”‚
                                  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                               â”‚  BaseAgent (ABC)   â”‚
                               â”‚  â€¢ run() async     â”‚
                               â”‚  â€¢ logs JSON       â”‚
                               â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚                                     â”‚
       DocumentExtractorAgent                PolicyCheckerAgent
```

*One `asyncio.Lock` gatekeeps the execution queue.  
Logs flow to stdout in structured JSON.*

---

## ğŸ›£ï¸ API Endpoints

| Method | Path | Purpose | Happy Response |
|--------|------|---------|----------------|
| `POST` | `/agents/run` | Kick off a run | `202 Accepted`, JSON `{run_id}` |
| `GET`  | `/agents/status/{run_id}` | Poll status / result | `200 OK`, JSON with `state` and `result` |

### Request Payload

```jsonc
{
  "agent_type": "document-extractor", // or "policy-checker"
  "user_id": "9b64a3a7-f8e4-4f06-8e57-73b50b042f29"
}
```

---

## ğŸš€ Why **FastAPI**?

| Feature                     | Benefit                                                                 |
|----------------------------|-------------------------------------------------------------------------|
| **Async-first design**     | Native `async`/`await` support for high-throughput non-blocking ops     |
| **Automatic OpenAPI docs** | FastAPI auto-generates an OpenAPI 3 spec + Swagger UI with no setup     |
| **Built-in Swagger UI**    | Available at [http://localhost:8080/docs](http://localhost:8080/docs)   |
| **Manual testing support** | Easily send POST/GET requests through browser without extra tools       |
| **Type safety**            | Request/response validation using Pydantic + Python typing              |

> Open `http://localhost:8080/docs` to interactively:
> - Trigger a new agent run (`POST /agents/run`)
> - Poll the agentâ€™s status (`GET /agents/status/{run_id}`)
> - See request and response schemas instantly

This makes the API self-documenting and user-friendly for developers and testers

## ğŸ¤– Agent Lifecycle

1. **START** â€“ logs `"Hello, I am a <agent-type> agent for <user-id>"`.
2. **EXECUTION** â€“ sleeps 5 s (placeholder for real work).
3. **COMPLETE** â€“ logs completion message.  
   *Policy-checker* additionally logs a random `"approved"` / `"rejected"`.
4. **States** exposed to clients: `PENDING` â†’ `RUNNING` â†’ `DONE` or `ERROR`.

---

## ğŸš¦ Single-Run Constraint & Trade-offs

| Why chosen             | Scaling path                                   | Drawbacks |
|------------------------|------------------------------------------------|-----------|
| *Business rule:* ensure deterministic access to single external mutexed resource (e.g., expensive licence).<br>*Simplicity:* one in-process lock, no DB needed. | â€¢ Swap `asyncio.Lock` for a distributed lock (Redis, DynamoDB Lease).<br>â€¢ Spin multiple runner replicas behind a queue and let the lock span pods.<br>â€¢ Or just allow concurrency once resource limits removed. | â€¢ Throughput = 1 â†’ latency spikes.<br>â€¢ App instance becomes single point of contention.<br>â€¢ Not horizontally scalable without redesign.|

Rejected requests return **`409 Conflict`** with JSON:

```json
{"detail": "An agent is already running, please retry later"}
```

---

## ğŸ§¯ Error Handling Strategy

| Scenario                       | Handling                                                  |
|--------------------------------|-----------------------------------------------------------|
| Unknown `agent_type`           | `400 Bad Request` + log `"Unsupported agent_type"`        |
| Agent code raises exception    | catch, log stack, mark run as `ERROR`, respond `500`      |
| Multiple run attempt while busy| `409 Conflict` (see above)                                |

> Faults are isolated; the server keeps serving subsequent requests.

---

## ğŸ” Structured Logging

All logs use `structlog` â†’ JSON with keys: `timestamp`, `level`, `event`,
`agent_type`, `user_id`, `run_id`. Example:

```json
{"timestamp":"2025-07-13T14:01:12Z","level":"info",
 "event":"agent_start","agent_type":"document-extractor",
 "user_id":"9b64...","run_id":"c4ff..."}
```

*These flow straight into CloudWatch / Datadog without parsing gymnastics.*

---



## ğŸ§ª Testing Approach



Run all:

```bash
pytest -q
```

## âš¡ Quick Start

```bash
git clone https://github.com/TayyabSuhail123/python-aws-api.git
cd python-aws-api
pip install -r requirements.txt
cp .env.example .env          # tweak LOG_LEVEL etc.
uvicorn main:app --reload     # â†’ http://localhost:8000
```

### Docker

```bash
docker build -t agent-runner .
docker run -p 8000:8000 --env-file .env agent-runner
```
---


---

## ğŸ› ï¸ CI/CD Pipeline (GitHub Actions)

This project uses a GitHub Actions workflow (`.github/workflows/docker-ecr.yml`) to build, test, scan, and push the Docker image to **AWS ECR** on every push to the `main` branch.

### ğŸ§© Steps Explained

| Step | Description |
|------|-------------|
| âœ… **Checkout code**         | Fetches the latest commit from `main` |
| ğŸ **Set up Python**         | Uses Python 3.10 |
| ğŸ“¦ **Install dependencies**  | Installs project packages from `requirements.txt` |
| ğŸ§ª **Run tests**             | Executes all `pytest` test cases. The build **fails if any test fails** |
| ğŸ” **Configure AWS**         | Authenticates using GitHub secrets and sets AWS region |
| ğŸ”‘ **Login to ECR**          | Logs into Amazon ECR using AWS credentials |
| ğŸ³ **Build Docker image**    | Builds the image and tags it as:  
`<account_id>.dkr.ecr.eu-central-1.amazonaws.com/agent-runner-repo:latest` |
| ğŸ›¡ï¸ **Trivy Security Scan**  | Scans the Docker image for **HIGH/CRITICAL** vulnerabilities and fails if found |
| ğŸš€ **Push to ECR**           | Pushes the image to your ECR repo if all checks pass |

> The pushed image is then used by the **ECS Fargate service** (provisioned in your separate Terraform repo) to deploy the backend container.

---

### ğŸ” GitHub Secrets Used

| Secret Name              | Purpose                         |
|--------------------------|---------------------------------|
| `AWS_ACCESS_KEY_ID`      | Access key for ECR push         |
| `AWS_SECRET_ACCESS_KEY`  | Secret key for ECR push         |

---

### ğŸš¦ Trigger

This workflow is configured with **`workflow_dispatch`**, meaning it only runs when you launch it manually:

1. Go to your repositoryâ€™s **Actions** tab.
2. Select **â€œBuild, Test, Scan, and Push to ECRâ€**.
3. Click **â€œRun workflowâ€**, choose the branch (default is `main`), and hit **Run**.

Because itâ€™s manual, edits to docs or README files no longer kick off the pipeline to push to ECR.

âš ï¸ **Note on Image Tagging**

For demo purposes, this pipeline always builds and pushes the Docker image with the `:latest` tag:

While convenient for quick iteration and manual testing, **using `latest` in production is strongly discouraged**.

### âŒ Problems with `latest` in production:
- No version pinning = no rollback capability
- Makes deployments non-reproducible
- Not a secure practise to use latest tag as an attacker may gain acces and deploy another latest version.

### âœ… Production Best Practice:
Tag every image with a unique version â€” typically the Git SHA or a semver:
```bash
docker tag agent-runner:abc123 <repo>:abc123

```

### ğŸ” Least-Privilege IAM Setup

A dedicated IAM user was created **only** for CI/CD pushes to ECR:

1. **User name**: `github-inca-CI`
2. **Access keys**: stored as GitHub Secrets  
   - `AWS_ACCESS_KEY_ID`  
   - `AWS_SECRET_ACCESS_KEY`
3. **Attached policy** minimum permissions for the demo (Can be further grained down)


## âœ… TODO â€“ Next Improvements

These enhancements are planned to move from demo-grade to production-grade setup:

- ğŸ”€ **Separate branches per environment** (e.g. `dev`, `staging`, `prod`)  
- âœ… **Merge Requests with approval required**  
  - Only approved MRs to `main` will trigger a CI pipeline that builds and pushes the image to ECR  
- ğŸ·ï¸ **Replace `:latest` tag with versioned tags**  
  - Git SHA or release versions will be used  
  - Enables proper rollback and traceability  
- ğŸ” **Secrets management with Vault**  
  - GitHub secrets will be replaced by a centralized **HashiCorp Vault setup**  
  - Each environment will have **isolated access policies**  
  - Prevents secrets from leaking across stages or services

These changes will help establish a secure, auditable, and production-ready delivery pipeline.


## ğŸ¤– AI Assistance in This Project

To accelerate development and maintain clarity under time constraints, this project leveraged **AI-assisted workflows** for:

- ğŸ“„ **Documentation drafting**: Accelerated README creation and structured formatting  
- âš™ï¸ **Architecture design feedback**: Validated initial architecture choices and suggested scalability trade-offs  
- ğŸ **Python error troubleshooting**: Helped debug async code and refine logging structure  
- ğŸ“¦ **CI/CD pipeline planning**: Assisted in planning a secure, minimal AWS deployment strategy via GitHub Actions  

All decisions were critically reviewed, and code was manually refined to ensure correctness and clarity.  
AI was treated as a **collaborator**, not an autopilot.
